# Equipo 6 üòé

Post works de evidencia para la Fase 3 del curso de Data Science de **Bedu**

## Integrantes:
 - Ang√©lica Luna Garc√≠a
 - Jes√∫s Iv√°n Mart√≠n Reyes
 - Julio Cesar Avila Padilla
 - Kimberly Atara Lopez Vazquez
 - Manuel Enrique Herrera Flores
 - Marco Antonio Hernandez Pe√±afort

## Postworks
## **1. Identificaci√≥n del problema**
---
### MARCO TE√ìRICO
La violencia en nuestro pa√≠s es un problema grave. Las 6 ciudades m√°s violentas del mundo est√°n en M√©xico (EL PA√çS, 2021). Durante el 2018 se cometieron 33 millones de delitos en todo el pa√≠s, asociados a 24.7 millones de v√≠ctimas, lo que significa que uno de cada tres hogares (33.9%) fue objeto de alg√∫n il√≠cito dicho a√±o (INEGI). 

En la CDMX, donde hay m√°s de 9 millones de habitantes (INEGI, 2020), domina la violencia, la inseguridad y, sobre todo, la impunidad. En la Ciudad de M√©xico, el 97.7 por ciento de los delitos queda impune. (M√©xico Eval√∫a, 2019).

Estos datos son sumamente alarmantes, pues muestran un claro problema que aqueja a la sociedad y, a pesar de esto, las autoridades no parecen estar atac√°ndolo de la manera correcta. 

‚ÄúEn nuestro pa√≠s existe una tendencia generalizada a no resolver y/o solucionar los delitos que se conocen, a pesar de que s√≥lo una peque√±a parte de los delitos ocurridos llegan al conocimiento de las autoridades.‚Äù

Mucho se ha especulado sobre este tema, muchos medios han publicado sus propios datos, y es por ello que nosotros hemos decidido trabajar con la base de datos OFICIAL que publica y actualiza el mismo gobierno capitalino, para poder identificar aquellas colonias y alcald√≠as en donde se cometen m√°s delitos, observar tendencias, y poder sugerir acciones para atacar aquellas zonas m√°s conflictivas.
### JUSTIFICACI√ìN
Se eligi√≥ trabajar en este dataset por m√∫ltiples razones:
-	Trata un tema de relevancia social, puesto que a todas y todos nos concierne nuestra seguridad y bienestar.
-	Transparencia en los datos: todos los ciudadanos de la Ciudad de M√©xico, aquellos de la zona metropolitana que frecuentan dicha ciudad, y otros visitantes ya sean habituales o espor√°dicos, tienen el derecho a poder consultar dicha informaci√≥n, de una manera sencilla y entendible, por lo que decidimos darnos a la tarea de limpiar y filtrar los datos para en un futuro cercano poder visualizarlos a trav√©s de gr√°ficos y mapas que faciliten su interpretaci√≥n y valoraci√≥n.
-	Al poder interpretar dicha informaci√≥n, nos podemos hacer cuestionamientos relevantes y forjarnos una opini√≥n acerca de la condici√≥n actual de seguridad en la CDMX, que nos permitan exigir a nuestros gobernantes (con base en informaci√≥n fidedigna) que atiendan con mayor eficacia aquellos delitos que se encuentran al alza y focalicen esfuerzos en aquellas delegaciones y colonias donde se muestren tendencias m√°s marcadas de delitos graves.
-	Es un proyecto escalable, puesto que, el an√°lisis que se haga de la CDMX, se puede replicar en otras ciudades del pa√≠s. El proyecto, adem√°s, tiene mucho potencial para posteriormente generar gr√°ficos, mapas y dem√°s figuras visuales que nos permitan interpretar a√∫n m√°s a fondo los datos.

## **2. Planteamiento de preguntas**
---
A trav√©s del an√°lisis de la base de datos elegida, pretendemos dar respuesta a los siguientes cuestionamientos:

- ¬øQu√© tipos de delitos se cometen con mayor frecuencia?
- ¬øEn qu√© colonias y alcald√≠as se cometen el mayor n√∫mero de delitos graves?
- ¬øQu√© tipos de delito han mostrado un crecimiento y decrecimiento en los √∫ltimos a√±os? ¬øEn qu√© medida?
- ¬øQu√© tipos de delitos son los que m√°s se cometen por alcald√≠a?
- ¬øQu√© delitos han son m√°s com√∫nes cada a√±o?
- ¬øHay horarios en el d√≠a en el que se cometen mayor n√∫mero de alg√∫n tipo de delito?

## 3. **Colecci√≥n de datos**
---
La colecci√≥n de datos se obtuvo del Portal de datos abietos del Gobierno de la Ciudad de M√©xico. La colecci√≥n se llama [*Carpetas de Investigaci√≥n de la FGJ*](https://archivo.datos.cdmx.gob.mx/fiscalia-general-de-justicia/carpetas-de-investigacion-fgj-de-la-ciudad-de-mexico/carpetas_completa_junio_2021.csv "Carpetas de Investigaci√≥n de la FGJ"), el cual puedes descargar en formato csv dando clic sobre el nombre. Si deseas descargarlo directamente de la p√°gina del Portal de datos abiertos, haz click [*aqu√≠*](https://datos.cdmx.gob.mx/dataset/carpetas-de-investigacion-fgj-de-la-ciudad-de-mexico/resource/48fcb848-220c-4af0-839b-4fd8ac812c0f "aqu√≠").

Esta base de datos contiene la informaci√≥n actualizada de las carpetas de investigaci√≥n de la Fiscal√≠a General de Justicia (FGJ) de la Ciudad de M√©xico a partir de enero de 2016. Las variables que contiene esta base son Carpetas de investigaci√≥n de delitos a nivel de calle de la FGJ por Fiscal√≠a, Agencia, Unidad de Investigaci√≥n, fecha de apertura de la carpeta de investigaci√≥n, delito, categor√≠a de delito, calle, colonia, alcald√≠a, coordenadas, mes y a√±o. Esta informaci√≥n se actualiza mensualmente.

## **4. An√°lisis exploratorio de datos**

### 4.1 Convertir el archivo CVS a un DataFrame de pandas
```python
# Realizamos la importaci√≥n de la librer√≠a pandas:
import pandas as pd

# Leemos el archivo csv y consultamos el tipo de archivo generado:
df = pd.read_csv('https://archivo.datos.cdmx.gob.mx/fiscalia-general-de-justicia/carpetas-de-investigacion-fgj-de-la-ciudad-de-mexico/carpetas_completa_junio_2021.csv', sep=',')
type(df)

```
### 4.2 An√°lisis exploratorio
```python
# Consultamos las dimensiones de nuestro 'df':
df.shape

# Consultamos las primeras 3 entradas del 'df':
df.head(3)

# Consultamos las √∫ltimas 3 entradas del 'df':
df.tail(3)

# Revisamos el tipo de datos de cada columna y si contienen NaN's:
df.info()
```
img_1
## **5. Limpieza de datos**

Antes de verificar la existencia de NaN eliminamos las columnas que no aportan informaci√≥n reelevante a nuestros objtivos y filtramos los datos a partir del a√±o en que existe mayor n√∫mero de registros de delitos y contenplando √∫nicamente las alcad√≠as de la CDMX.

### 5.1 Eliminando columnas
```python
# Eliminando 6 columnas que no ser√°n parte del analisis:
df_dropped = df.drop(columns=["unidad_investigacion", "agencia", "tempo", "competencia", "calle_hechos", "calle_hechos2"])
df_dropped.info()
```
### 5.2 Filtrando los datos
```python
# Analizamos a  partir de qu√© a√±o es pertinente filtrar los datos de acuerdo a la incidencia de delitos:
df_dropped.groupby('ao_hechos')['categoria_delito'].count().tail(20)

# Con base en lo anterior decidimos filtrar los datos a partir del 'ao_hechos'>=2016:
df_filtrado_1=df_dropped.loc[df_dropped['ao_hechos']>=2016]
print(df_filtrado_1.head(3))
print(df_filtrado_1.info())

# Contamos cu√°ntas alcald√≠as est√°n presentes en el df 'df_filtrado_1':
df_filtrado_1['alcaldia_hechos'].unique()

# Al notar que la columna 'alcaldia_hechos' contiene alcald√≠as de todo el pa√≠s, filtramos √∫nicamente aquellas que corresponden a la CDMX
# (16 alcald√≠as):
alcadias_cdmx = ['BENITO JUAREZ',
  'IZTAPALAPA',
  'CUAUHTEMOC',
  'TLAHUAC',
  'IZTACALCO',
  'GUSTAVO A MADERO',
  'MIGUEL HIDALGO',
  'TLALPAN',
  'ALVARO OBREGON',
  'VENUSTIANO CARRANZA',
  'AZCAPOTZALCO',
  'CUAJIMALPA DE MORELOS',
  'COYOACAN',
  'XOCHIMILCO',
  'LA MAGDALENA CONTRERAS',
  'MILPA ALTA'
 ]

df_filtrado_2 = df_filtrado_1.loc[df_filtrado_1['alcaldia_hechos'].isin(alcadias_cdmx)]
print(df_filtrado_2["alcaldia_hechos"].unique())
print("\n")
print(df_filtrado_2.info())
```
### 5.3 Eliminando los NaN 

```python
# Contamos cu√°ntos NaN existen en cada columna:
df_filtrado_2.isna().sum()

# Ahora eliminamos las filas que contienen puros NaN (si las hay):
df_sin_nan_1=df_filtrado_2.dropna(axis=0, how='all')
df_sin_nan_1

# Al ejecutar la  instrucci√≥n anterior no se elimin√≥ ninguna fila, por lo que se asume que ninguna fila conten√≠a puros NaN.

# Ahora eliminamos los registros con NaN en las columnas de fecha_inicio y fiscalia, debido a su poca signficancia estad√≠stica:
df_sin_nan_2 = df_sin_nan_1.loc[df_sin_nan_1['fiscalia'].notna()]
df_sin_nan_3 = df_sin_nan_2.loc[df_sin_nan_2['fecha_inicio'].notna()]
df_sin_nan_4 = df_sin_nan_3.loc[df_sin_nan_3["latitud"].notna()]
df_sin_nan_5 = df_sin_nan_4.loc[df_sin_nan_4["longitud"].notna()]

df_sin_nan_5.isna().sum()

# Ahora remplazamos los NaN de la columna 'colonia_hechos' por la palabra Unknown para eliminar completamente los NaN:
df_sin_nan_5["colonia_hechos"] = df_sin_nan_5["colonia_hechos"].fillna('Unknown')
df_sin_nan_5.isna().sum()

# En los casos en los que la latitud y longitud no existe se evaluar√° posteriormente la posibilidad de colocar la latitud y longitud de la alcadia de
# acuerdo a datos del gobierno de la CDMX: https://datos.cdmx.gob.mx/dataset/bae265a8-d1f6-4614-b399-4184bc93e027/resource/e4a9b05f-c480-45fb-a62c-6d4e39c5180e/download/alcaldias.csv

# lat_long_alcaldias = pd.read_csv("https://datos.cdmx.gob.mx/dataset/bae265a8-d1f6-4614-b399-4184bc93e027/resource/e4a9b05f-c480-45fb-a62c-6d4e39c5180e/download/alcaldias.csv")


```
### 5.4 Reseteando los √≠ndices
```python
# Reseteamos los indices, pues hemos eliminado algunas filas:
df_indice_reseteado = df_sin_nan_5.reset_index(drop=True)
print(df_indice_reseteado.shape)
print('\n')
print(df_indice_reseteado.head(3))
print('\n')
print(df_indice_reseteado.tail(3))
```
